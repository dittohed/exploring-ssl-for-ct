{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to visualize model predictions and evaluate it\n",
    "(sanity check)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.utils as utils\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    ScaleIntensityRanged,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    SpatialPadd\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.utils.enums import MetricReduction\n",
    "\n",
    "from src.loaders import get_finetune_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHKPT_PATH = '../chkpts/test.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data = get_finetune_data('../data/finetune/')\n",
    "\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=['img', 'label']),\n",
    "    EnsureChannelFirstd(keys=['img', 'label']),\n",
    "    Orientationd(keys=['img', 'label'], axcodes='RAS'),\n",
    "    Spacingd(keys=['img', 'label'], pixdim=(1.5, 1.5, 2), \n",
    "                mode=('bilinear', 'nearest')),\n",
    "    ScaleIntensityRanged(keys=['img'], a_min=-175, a_max=250,\n",
    "                            b_min=0.0, b_max=1.0, clip=True),\n",
    "    CropForegroundd(keys=['img', 'label'], source_key='img'),\n",
    "    SpatialPadd(keys=['img', 'label'], spatial_size=(96, 96, 96)),\n",
    "    EnsureTyped(keys=['img', 'label'], track_meta=False)\n",
    "])\n",
    "\n",
    "ds = Dataset(\n",
    "    data=data, \n",
    "    transform=transforms\n",
    ")\n",
    "    \n",
    "loader = DataLoader(\n",
    "    ds, \n",
    "    num_workers=0, \n",
    "    batch_size=1, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    feature_size=12,\n",
    "    num_heads=(3, 3, 3, 3)\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(CHKPT_PATH, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "model_infer = partial(\n",
    "    sliding_window_inference,\n",
    "    roi_size=[96, 96, 96],\n",
    "    sw_batch_size=1,\n",
    "    predictor=model,\n",
    "    overlap=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fn = DiceMetric(include_background=True, reduction=MetricReduction.MEAN, get_not_nans=True)\n",
    "post_label = AsDiscrete(to_onehot=14)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation dice score: 0.0906\n"
     ]
    }
   ],
   "source": [
    "avg_agg = utils.AverageAggregator()\n",
    "\n",
    "for data_dict in loader:\n",
    "    img, label = data_dict['img'].to(device), data_dict['label'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model_infer(img)\n",
    "\n",
    "    label_list = decollate_batch(label)\n",
    "    label_list = [post_label(label_tensor) for label_tensor in label_list]\n",
    "    pred_list = decollate_batch(pred)\n",
    "    pred_list = [post_pred(pred_tensor) for pred_tensor in pred_list]\n",
    "\n",
    "    # Store visualizations\n",
    "    for i in range(img.shape[-1]):\n",
    "        if i % 50 == 0:\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "            axs[0].imshow(img[0, 0, :, :, i], cmap='gray', vmin=0, vmax=1)\n",
    "            axs[0].set_title('Original slice')\n",
    "            axs[1].imshow(label[0, 0, :, :, i])\n",
    "            axs[1].set_title('Label')\n",
    "            axs[2].imshow(torch.argmax(pred[0, :, :, :, i], dim=0))\n",
    "            axs[2].set_title('Prediction')\n",
    "\n",
    "            file_id = Path(data_dict[\"img_meta_dict\"][\"filename_or_obj\"][0]).stem\n",
    "            plt.savefig(f'{file_id}_{i}.png')\n",
    "            plt.close()\n",
    "\n",
    "    acc_fn.reset()\n",
    "    acc_fn(y_pred=pred_list, y=label_list)\n",
    "    acc, not_nans = acc_fn.aggregate()\n",
    "    assert not_nans == 1\n",
    "    avg_agg.update(acc.item())\n",
    "\n",
    "print(f'Mean validation dice score: {avg_agg.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sslct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
